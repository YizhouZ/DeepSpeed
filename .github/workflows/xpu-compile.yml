name: xpu-compile

on:
  workflow_dispatch:
  schedule:
    - cron: "0 0 * * *"
  pull_request:
    paths:
      - ".github/workflows/xpu-compile.yml"
      - "accelerator/xpu_accelerator.py"
      - "accelerator/abstract_accelerator.py"
      - "accelerator/cpu_accelerator.py"
      - "accelerator/real_accelerator.py"
      - "csrc/xpu/**"
      - "deepspeed/runtime/engine.py"
      - "deepspeed/runtime/bf16_optimizer.py"
      - "deepspeed/runtime/zero/stage_1_and_2.py"
      - "deepspeed/runtime/zero/stage3.py"
      - "deepspeed/runtime/zero/partition_parameters.py"
      - "deepspeed/runtime/zero/partitioned_param_coordinator.py"
      - "deepspeed/runtime/zero/parameter_offload.py"
      - "deepspeed/runtime/pipe/engine.py"
      - "deepspeed/runtime/utils.py"
      - "op_builder/xpu/**"

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

permissions:
  contents: read
  issues: write


jobs:
  unit-tests:
    runs-on: [self-hosted, torch_compile_2]
    # container:
    #   image: intel/oneapi-basekit:2024.1.1-devel-ubuntu22.04
    #   ports:
    #     - 80
    #   options: --privileged -it --rm --device /dev/dri:/dev/dri -v /dev/dri/by-path:/dev/dri/by-path --ipc=host --cap-add=ALL

    steps:
    - uses: actions/checkout@v4
    - name: Install prerequisite
      run: |
        apt-get update
        apt-get install clinfo libaio-dev python3-pip -y
        pip install torch==2.3.1 -f https://pytorch-extension.intel.com/release-whl/stable/xpu/us/torch/
        pip install intel-extension-for-pytorch==2.3.110+xpu -f https://pytorch-extension.intel.com/release-whl/stable/xpu/us/intel-extension-for-pytorch/
        pip install oneccl_bind_pt==2.3.100+xpu -f https://pytorch-extension.intel.com/release-whl/stable/xpu/us/oneccl-bind-pt/
        pip install torchvision==0.18.1 -f https://pytorch-extension.intel.com/release-whl/stable/xpu/us/torchvision/
        pip install py-cpuinfo numpy
        pip install .[dev,autotuning]

    - name: Check container state
      run: |
        ldd --version
        ds_report
        python3 -c "import torch; print('torch:', torch.__version__, torch)"
        python3 -c "import torch; import intel_extension_for_pytorch; print('XPU available:', torch.xpu.is_available())"
        python3 -c "from deepspeed.accelerator import get_accelerator; print('accelerator:', get_accelerator()._name)"
        pip list

    - name: Compile Status
      run: |
        cd tests/torch_compile
        export ZE_AFFINITY_MASK=0,1
        deepspeed compile_graph_break.py --deepspeed_config ds_config.json |& tee log.txt
        GITHUB_STEP_SUMMARY=$(cat log.txt |  grep "'graph_breaks'" | sed 's/,/ /g' | awk '{print $2}')
